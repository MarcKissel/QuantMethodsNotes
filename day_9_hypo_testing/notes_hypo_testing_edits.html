<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Hypothesis Testing</title>
    <meta charset="utf-8" />
    <meta name="author" content="" />
    <meta name="date" content="2019-03-20" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Hypothesis Testing
### 2019-03-20

---






#today's class

## short updates
## hypothesis testing
## group projects, homework assignment, &amp; any questions

---
## online quiz next week
## in class quiz on the 3rd (do the assigned readings)
## topic overview on 4/3
## 4/10 - no class but work on projects &amp; homework assignment about hypothesis testing
##5/1 Presentations


# all things due by May 6th!

---
#hypothesis testing!
These  notes come mostly from LSWR and Modern Dive readings...


![](https://media.tenor.com/images/4499c00cb6446e066b244a7859f695af/tenor.gif)


---

###research hypotheses - a substantive &amp; testable scientific claim. so a claim about human evolution/behavior/etc

What makes a good research hypotheses

###Statistical hypotheses - mathematical precise &amp; correspond to specific claims about the characteristics of the data generating mechanism

##we  want to map our **research hypothesis** onto our **stats hypothesis**


---


# example:  
# my research hypothesis is that brain size increases within a speices 

--


# my statistical hypothesis is that the mean of population 1 and mean of population 2 are equal


##A statistical hypothesis test is a test of the statistical hypothesis, *not* the research hypothesis

---

in a group come up with 4 different hypotheses related to anthropology. 


---

#step 2
________

## figure out your **null hypothesis**:

#lets say my null will be that brain size stays the same with a hominin species, so μ1 = μ2

#we assume the null is true unless we can prove otherwise. like a court case it is *innocent* until proven guilty. 

---
# Two types of errors

|keep null|reject null
-|-|-
null is true|correct|type 1 error
null is false|type 2 error|correct

##if i get heads 10 times in a row what does that mean? 1/1024 chance that happens with a fair coin 

---

##Want to control the probability of a Type 1 error, which is labeled as α. Why? if someone is innocent we don't want to send them to jail..

---

## but we want to keep both α and β small

β = probability of a type 2 error 

Power = probability with which we reject a null hypothesis when it really is false ( 1 -  β)

A good test has a small β while also keeping α at a small number 


|keep null|reject null
-|-|-
null is true|1 -α (correct retention) |α
null is false|β	|1- β	(power)



---
#Test statistic and sampling dist

###let's imagine we want to test for ESP.

###in a small group think about how you can do this:

## - what would be the sci hypothesis and the statistical hypothesis
## - What is the null

## - what problems might you run into



---

###null = no ESP. if null is true, what do we expect? 

###50 people get right? or 57? 99? 8?

### have a quantity X that we can calculate by looking at our data; after looking at the value of X, we make a decision about whether to believe that the null hypothesis is correct, or to reject the null hypothesis in favor of the alternative. This is the **test statistic**

##What values of the test stat would cause us to reject the null?


---

# We ask what the **sampling distribution of the test statistic** would be if the null hypothesis were actually true


### in this  case, this is a binomial

 
---


![](https://learningstatisticswithr.com/book/lsr_files/figure-html/samplingdist-1.png)


???
: The sampling distribution for our test statistic  X
  when the null hypothesis is true. For our ESP scenario, this is a binomial distribution. Not surprisingly, since the null hypothesis says that the probability of a correct response is  
θ=.5
 , the sampling distribution says that the most likely value is 50 (our of 100) correct responses. Most of the probability mass lies between 40 and 60.

---

#Critical regions and critical values
 
##What values of the test statistic *X* should lead us to reject the null?

## **critical region**  corresponds to  values of X that would lead us to reject null hypothesis

 - X should be very big or very small in order to reject the null hypothesis.
 

 - If α = .05, the critical region must cover 5% of this sampling distribution.


---

![](https://learningstatisticswithr.com/book/lsr_files/figure-html/crit2-1.png)

the critical region consists of the most extreme values, known as the tails of the distribution

---
# For this example, our critical regions correspond to X &lt;= 40 and X &gt;= 60


1. we choose a α level
2. came up with some test statistic that does a good job of comparing
H0 to H1
3. figured out the sampling distribution of the test statistic on the assumption that the null
hypothesis is true (in this case, binomial)
4. calculate the critical region that produces an appropriate α level (0-40 and 60-100).

in this case, X = 62 and we may  say that the test has produced a significant result.

---

## one-sided vs. two-sided test

![](https://learningstatisticswithr.com/book/lsr_files/figure-html/crit1-1.png)


---
# P-values


value of α|reject null?
-|-|-
 .05|Yes
 .04|Yes
 .03|Yes
 .02|NO
 .01|NO

if X = 62, then we would reject null if we set α to .02 


### p can be defined as the smallest Type I error rate (α) that you have to be willing to tolerate if you want to reject the null hypothesis.

fyi: In our example, p-value = .021

p ≤ α then reject
P &gt; α not reject

---


or, we can define it like this:

###The probability that we would have observed a test statistic that is at least as extreme as the one we actually did get. If the data are extremely implausible according to the null hypothesis, then the null hypothesis is probably wrong.

---

both defs are ok
________


#What is wrong is if you say p value is "the probability that the null hypothesis is true".

- the null is either true or false.



---

lets try in R
n = 100
prob of success, given null  = .5
X = 62



```r
binom.test( x =  62, n=100, p = .5)
```

```
## 
## 	Exact binomial test
## 
## data:  62 and 100
## number of successes = 62, number of trials = 100, p-value =
## 0.02098
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.5174607 0.7152325
## sample estimates:
## probability of success 
##                   0.62
```


---
#what is your effect size?

we also want to minimize β. let's face it, we don't want to fail to reject when the null actually is wrong!

Stats folks talk about maximizing the power of the test.

power = 1 - β


"In plain English, statistical power is the likelihood that a study will detect an effect when there is an effect there to be detected. If statistical power is high, the probability of making a Type II error, or concluding there is no effect when, in fact, there is one, goes down."

https://istats.shinyapps.io/power/




---

#effect size
 
a way toquantifying how **similar** the
true state of the world is to the null hypothesis. 
Or, how big is the difference between the true population parameters, and the parameter values that are assumed by the null hypothesis?

difference in ESP study between theta  = .51 and theta = .8


---

#lets practice



then think about what your research and statistical hypothesis for your project are. 
think about the sci hypo, the stat hypo, what the null and alt hypo is, what the sampling dist is, and how you might test?
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
